

# Matrix things below

Not relevant yet ...

```{python}
import numpy as np

def make_np_matrix_progression(svals, summands):
    # svals: numpy vector of starting values
    # summands: numpy vector of integer summands

    dims = (len(svals), len(svals))
    x = np.broadcast_to(np.array([svals]).T, dims)
    summands = np.broadcast_to(np.array([summands]).T, dims)

    adder_mat = np.broadcast_to(np.arange(0, dims[0]), dims)

    return(x + adder_mat*summands)


def format_matrix_row(row):
    return("".join(["[ " + str(i) + "]" for i in row]))


def format_digit_matrix(m, mask=None):

    mat_list = [list(i) for i in m]

    if mask is None:
        string_out = "\n".join([format_matrix_row(r) for r in mat_list])

    else:
        mat_list[-1] = mat_list[-1][:-1]
        string_out = "\n".join([format_matrix_row(r) for r in mat_list])
        string_out = string_out + mask

    return(string_out)    
```


```{python}
def make_np_matrix_constant(svals):
    # svals: numpy vector of starting values

    dims = (len(svals), len(svals))
    x = np.broadcast_to(np.array([svals]).T, dims)

    return(x)


def make_np_matrix_dist(svals):
    # svals: numpy vector of starting values

    dims = (len(svals), len(svals))

    x = np.array([
        svals,
        svals[[1, 2, 0]],
        svals[[2, 0, 1]]
        ])

    return(x)
```


```{python}
def mix_matrix_row(r1, r2):
    return("".join(["[ " + str(r1[i]) + " " + str(r2[i]) + "]" for i in range(0, len(r1))]))

def mix_matrices(m1, m2, mask=None):

    m1_list = [list(i) for i in m1]
    m2_list = [list(i) for i in m2]

    if mask is None:
        string_out = "\n".join([mix_matrix_row(m1_list[i], m2_list[i]) for i in range(0, len(m1_list))])

    else:
        m1_list[-1] = m1_list[-1][:-1]
        m2_list[-1] = m2_list[-1][:-1]
        string_out = "\n".join([mix_matrix_row(m1_list[i], m2_list[i]) for i in range(0, len(m1_list))])
        string_out = string_out + mask

    return(string_out)

x1 = make_np_matrix_progression(np.array([11, 22, 33]), np.array([1, 2, 3]))
x2 = make_np_matrix_constant(np.array([41, 51, 61]))


print(mix_matrices(x1, x2))
```

I can make a lot of different matrices instantiating each of the individual relations while keeping the numbers in the realm of two-digits, and also while ensuring there are two distinct sets, an out of sample set for validation that has none of the same tokens as the created set.

Using the first 50 digits as "within sample" and the last 50 digits as "out of sample", there are in each group:

- constant: 50 choose 3 matrices that can be made, or 19600.
- distribution of three: 50 choose 3 matrices that can be made, or 19600.
- progression: 30 choose 3 = 4060 first vectors and 9 choose 3 = 84 summands, or ~341k matrices that can be made.
- two-rule: all combinations of these, so millions
- could also possibly add some new relations:
    - fibonnaci (sum of last two numbers) (looks like it can 1-shot) -- can't have very many of these tho
    - successive doubling (looks like it can 1-shot) -- can have about 24x24x24 = 13824 of these

In terms of relation-pairs, there are 6 different kinds:

1. constant - constant
2. distribution - distribution
3. progression - progression
4. constant - distribution
5. constant - progression
6. distribution - progression

Ignoring order (or keeping it fixed), we can have 6 different kinds of two-rule matrices. If we care about order, we can have 9 different kinds. And in terms of matrix pairs, we can have 6 choose 2 = 15 different if we don't care about order (or keep it fixed) and can have 9 choose 2 = 36 different if we do care about order.

If we extend to three-rule matrices, we can ahve 20 different kinds of three-rule matrices. In terms of matrix pairs, we can have 20 choose 2 = 190 different relation pairs if we don't care about order (or keep it fixed).

So going all the way to three-rule matrices gives us quite a few different kinds of matrices to work with, and to consider "out of sample". 

I think so long as we are focused on few-shot learning, then using 2-rule will be fine. We can give 3 "same" examples and 3 "different" examples and still have 3 and 6 oos examples to test on. And/or we can do a leave-out-one-relation cross-validation approach always holding one out.

Or if we add the two extra relation types, then the math changes somewhat. We can have 10 different pairs of one-rule matrices, so could possibly get away with all one-rule matrices. If we incorporate that all into two rule matrices, then we can have 10 choose 2 = 45 different pairs of two-rule matrices (10 same, 35 different). 


----

Looking ahead, I think that this syntax will be the best. Key is to make sure there is the leading space ahead of the important tokens. This lets a one-rule matrix for 23 tokens, and a 2-rule for 31 tokens.

```
[ 1][ 1][ 1]
[ 2][ 2][ 2]
[ 3][ 3][ 3]
```

Should be able to do 16-shot prompting even with 3-rule problems (~2560 tokens). But can't quite fit 32-shot with more than one rule. So will have to turn to fine-tuning to give more examples.


### Some tests on GPT-3

Looks like it's quite sensitive to the formatting of the input. The best approach I think will be to find a zero-shot syntax that works for the basic case of RMTS between words/tokens. Then I can use the same syntax for the more complex cases of RMTS between number matrices.


```
[ car ]
[ boat ]
----
[ boat ]
[ ? ]

? is:
A: [ boat ]
B: [ airplane ]

Answer:
```

```
< 
car
>
<
boat
>
----
<
boat
>
<
?
>

? is:
A:
<
boat
>
B
<
airplane
>

Answer: B: <airplane>
```

```
<
[ 1 ] [ 1 ] [ 1 ]
[ 2 ] [ 2 ] [ 2 ]
[ 3 ] [ 3 ] [ 3 ]
>
<
[ 6 ] [ 6 ] [ 6 ]
[ 3 ] [ 3 ] [ 3 ]
[ 1 ] [ 1 ] [ 1 ]
>
----
<
[ 5 ] [ 5 ] [ 5 ]
[ 2 ] [ 2 ] [ 2 ]
[ 0 ] [ 0 ] [ 0 ]
>
<
 ?
>

? is:
A:
<
[ 5 ] [ 2 ] [ 0 ]
[ 2 ] [ 0 ] [ 5 ]
[ 0 ] [ 5 ] [ 2 ]
>
B: 
<
[ 8 ] [ 8 ] [ 8 ]
[ 5 ] [ 5 ] [ 5 ]
[ 3 ] [ 3 ] [ 3 ]
>

Answer:
```

